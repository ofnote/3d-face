import argparse
from numba.cuda import test
from tqdm import tqdm
import torch
from decalib.datasets import datasets
from decalib.utils.config import cfg as deca_cfg
from decalib.utils import util
from decalib.decaCoarse import DecaCoarse
import os
import sys
import cv2


def main(args):
    savefolder = args.savefolder
    device = args.device
    os.makedirs(savefolder, exist_ok=True)
    testdata = datasets.TestData(
        args.inputpath, iscrop=args.iscrop, face_detector=args.detector)

    decaCoarse = DecaCoarse(
        path='savedModel/decaCoarse-epoch=04-valid_loss=254.23.ckpt', config=deca_cfg, device=device)

    for i in tqdm(range(len(testdata))):
        name = testdata[i]['imagename']
        images = testdata[i]['image'].to(device='cuda')[None, ...]

        codedict = decaCoarse.encode(images)
        decodedict = decaCoarse.decode(codedict)
        util.showImage(decodedict['shape_image'])
    #     if args.saveDepth or args.saveKpt or args.saveObj or args.saveMat or args.saveImages:
    #         os.makedirs(os.path.join(savefolder, name), exist_ok=True)
    #     # -- save results
    #     if args.saveDepth:
    #         depth_image = deca.render.render_depth(
    #             opdict['transformed_vertices']).repeat(1, 3, 1, 1)
    #         visdict['depth_images'] = depth_image
    #         cv2.imwrite(os.path.join(savefolder, name, name +
    #                     '_depth.jpg'), util.tensor2image(depth_image[0]))
    #     if args.saveKpt:
    #         np.savetxt(os.path.join(savefolder, name, name +
    #                    '_kpt2d.txt'), opdict['landmarks2d'][0].cpu().numpy())
    #         np.savetxt(os.path.join(savefolder, name, name +
    #                    '_kpt3d.txt'), opdict['landmarks3d'][0].cpu().numpy())
    #     if args.saveObj:
    #         deca.save_obj(os.path.join(
    #             savefolder, name, name + '.obj'), opdict)
    #     if args.saveMat:
    #         opdict = util.dict_tensor2npy(opdict)
    #         savemat(os.path.join(savefolder, name, name + '.mat'), opdict)
    #     if args.saveVis:
    #         cv2.imwrite(os.path.join(savefolder, name + '_vis.jpg'),
    #                     deca.visualize(visdict))
    #     if args.saveImages:
    #         for vis_name in ['inputs', 'rendered_images', 'albedo_images', 'shape_images', 'shape_detail_images']:
    #             if vis_name not in visdict.keys():
    #                 continue
    #             image = util.tensor2image(visdict[vis_name][0])
    #             cv2.imwrite(os.path.join(savefolder, name, name + '_' +
    #                         vis_name + '.jpg'), util.tensor2image(visdict[vis_name][0]))
    # print(f'-- please check the results in {savefolder}')


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description='DECA: Detailed Expression Capture and Animation')
    parser.add_argument('-i', '--inputpath', default='TestSamples/examples', type=str,
                        help='path to the test data, can be image folder, image path, image list, video')
    parser.add_argument('-s', '--savefolder', default='TestSamples/examples/results', type=str,
                        help='path to the output directory, where results(obj, txt files) will be stored.')
    parser.add_argument('--device', default='cuda', type=str,
                        help='set device, cpu for using cpu')
    # process test images
    parser.add_argument('--iscrop', default=True, type=lambda x: x.lower() in ['true', '1'],
                        help='whether to crop input image, set false only when the test image are well cropped')
    parser.add_argument('--detector', default='fan', type=str,
                        help='detector for cropping face, check decalib/detectors.py for details')
    # save
    parser.add_argument('--useTex', default=False, type=lambda x: x.lower() in ['true', '1'],
                        help='whether to use FLAME texture model to generate uv texture map, \
                            set it to True only if you downloaded texture model')
    parser.add_argument('--saveVis', default=True, type=lambda x: x.lower() in ['true', '1'],
                        help='whether to save visualization of output')
    parser.add_argument('--saveKpt', default=False, type=lambda x: x.lower() in ['true', '1'],
                        help='whether to save 2D and 3D keypoints')
    parser.add_argument('--saveDepth', default=False, type=lambda x: x.lower() in ['true', '1'],
                        help='whether to save depth image')
    parser.add_argument('--saveObj', default=False, type=lambda x: x.lower() in ['true', '1'],
                        help='whether to save outputs as .obj, detail mesh will end with _detail.obj. \
                            Note that saving objs could be slow')
    parser.add_argument('--saveMat', default=False, type=lambda x: x.lower() in ['true', '1'],
                        help='whether to save outputs as .mat')
    parser.add_argument('--saveImages', default=False, type=lambda x: x.lower() in ['true', '1'],
                        help='whether to save visualization output as seperate images')
    main(parser.parse_args())
